{
  "os": "Linux-5.4.0-216-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.11.10",
  "startedAt": "2026-02-13T12:42:42.320598Z",
  "args": [
    "--deepspeed",
    "./scripts/zero3.json",
    "--model_name_or_path",
    "/data1/hbshim/Qwen3-VL/qwen-vl-finetune/output_alignment",
    "--dataset_use",
    "train_dataset",
    "--eval_dataset_use",
    "eval_dataset",
    "--data_flatten",
    "False",
    "--data_packing",
    "False",
    "--tune_mm_vision",
    "False",
    "--tune_mm_mlp",
    "True",
    "--tune_mm_llm",
    "True",
    "--lora_enable",
    "True",
    "--lora_r",
    "64",
    "--lora_alpha",
    "128",
    "--lora_dropout",
    "0.05",
    "--bf16",
    "--output_dir",
    "./output_lora-instruction-tune",
    "--num_train_epochs",
    "1",
    "--per_device_train_batch_size",
    "1",
    "--per_device_eval_batch_size",
    "1",
    "--gradient_accumulation_steps",
    "16",
    "--max_pixels",
    "25088",
    "--min_pixels",
    "784",
    "--eval_strategy",
    "steps",
    "--eval_steps",
    "300",
    "--save_strategy",
    "steps",
    "--save_steps",
    "300",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-3",
    "--weight_decay",
    "0.05",
    "--warmup_ratio",
    "0.03",
    "--max_grad_norm",
    "1",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--model_max_length",
    "4096",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--run_name",
    "qwen2.5vl-lora-instruction-tune",
    "--report_to",
    "wandb"
  ],
  "program": "/data1/hbshim/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePath": "qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePathLocal": "qwenvl/train/train_qwen.py",
  "git": {
    "remote": "https://github.com/HBShim03/Qwen3-VL.git",
    "commit": "14ff7b1bd52b5f50553fbc608e6807716f38ebc4"
  },
  "email": "hanbo0918@gmail.com",
  "root": "/data1/hbshim/Qwen3-VL/qwen-vl-finetune",
  "host": "a92656140b07",
  "executable": "/opt/conda/bin/python3.11",
  "cpu_count": 40,
  "cpu_count_logical": 40,
  "gpu": "NVIDIA GeForce RTX 2080 Ti",
  "gpu_count": 4,
  "disk": {
    "/": {
      "total": "7937302376448",
      "used": "6324762333184"
    }
  },
  "memory": {
    "total": "270058516480"
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 2080 Ti",
      "memoryTotal": "11811160064",
      "cudaCores": 4352,
      "architecture": "Turing",
      "uuid": "GPU-6ce34bdf-71c9-33e2-3b19-3ceeab2361a3"
    },
    {
      "name": "NVIDIA GeForce RTX 2080 Ti",
      "memoryTotal": "11811160064",
      "cudaCores": 4352,
      "architecture": "Turing",
      "uuid": "GPU-01c585cc-7afd-5ca6-4d78-7f968589d4ff"
    },
    {
      "name": "NVIDIA GeForce RTX 2080 Ti",
      "memoryTotal": "11811160064",
      "cudaCores": 4352,
      "architecture": "Turing",
      "uuid": "GPU-55419a04-766f-fd72-b7ca-767779f0d0ff"
    },
    {
      "name": "NVIDIA GeForce RTX 2080 Ti",
      "memoryTotal": "11811160064",
      "cudaCores": 4352,
      "architecture": "Turing",
      "uuid": "GPU-ae26444b-929e-cd80-4527-e144bab08e16"
    }
  ],
  "cudaVersion": "12.2",
  "writerId": "89gcj1kaz5n452tya0hsznbnch6ldzw6"
}